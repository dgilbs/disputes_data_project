{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning:\n",
      "\n",
      "pylab import has clobbered these variables: ['test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as ply\n",
    "from datetime import date\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disputes = pd.read_csv(\"/Users/danielgilberg/data_science/metis/practice/mcnulty/data/MID-level/MIDA_4.01.csv\")\n",
    "dispute_part = pd.read_csv(\"/Users/danielgilberg/data_science/metis/practice/mcnulty/data/MID-level/MIDB_4.01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = (disputes.HostLev>=3 ) & (disputes.Fatality > 0) \n",
    "major_events = disputes[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "military_df = pd.read_csv(\"/Users/danielgilberg/data_science/metis/practice/mcnulty/data/NMC_5_0/NMC_5_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "military_df = military_df.rename(columns={\"year\": \"StYear\", \"version\":\"Version\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "participant_info = pd.merge(dispute_part, military_df, on=[\"ccode\", \"StYear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DispNum3', 'DispNum4', 'StAbb', 'ccode', 'StDay', 'StMon', 'StYear',\n",
       "       'EndDay', 'EndMon', 'EndYear', 'SideA', 'RevState', 'RevType1',\n",
       "       'RevType2', 'Fatality', 'FataPre', 'HiAct', 'HostLev', 'Orig',\n",
       "       'Version_x', 'stateabb', 'milex', 'milper', 'irst', 'pec', 'tpop',\n",
       "       'upop', 'cinc', 'Version_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DispNum3', 'DispNum4', 'StAbb', 'ccode', 'StDay', 'StMon', 'StYear',\n",
       "       'EndDay', 'EndMon', 'EndYear', 'SideA', 'RevState', 'RevType1',\n",
       "       'RevType2', 'Fatality', 'FataPre', 'HiAct', 'HostLev', 'Orig',\n",
       "       'stateabb', 'milex', 'milper', 'irst', 'pec', 'tpop', 'upop', 'cinc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_info = participant_info.drop([\"Version_x\", \"Version_y\"], axis=1)\n",
    "participant_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dispute_side_info = participant_info.groupby([\"DispNum3\", \"DispNum4\"], as_index=False).agg({\"milex\": sum, \n",
    "                                                                                \"milper\": sum, \"irst\": sum,\n",
    "                                                                                \"tpop\": sum, \"upop\":sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_major_event(fatality, hostility):\n",
    "    if fatality > 0 and hostility > 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "disputes[\"Major_Dispute\"] = disputes.apply(lambda row: is_major_event(row[\"Fatality\"], row[\"HostLev\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sides = pd.merge(disputes, dispute_side_info, on=[\"DispNum3\", \"DispNum4\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_df = pd.read_csv(\"/Users/danielgilberg/data_science/metis/practice/mcnulty/data/COW_Trade_4.0/National_COW_4.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trade_df = trade_df[[\"ccode\", \"statename\", \"stateabb\", \"year\", \"imports\", \"exports\"]]\n",
    "# trade_df = trade_df.rename(columns={\"year\": \"StYear\"})\n",
    "# df = pd.merge(participant_info, trade_df, on=[\"ccode\", \"StYear\"])\n",
    "trade_df = df.groupby([\"ccode\", \"StYear\"], as_index=False).agg({\"imports\": sum, \"exports\": sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disputes_with_trade = dispute_part.merge(trade_df, on=[\"ccode\", \"StYear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_trade = disputes_with_trade.groupby([\"DispNum3\", \"DispNum4\"], as_index=False).agg({\"imports\": sum, \"exports\": sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sides = pd.merge(all_sides, total_trade, on=[\"DispNum3\", \"DispNum4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sides[\"imports\"] = all_sides.imports.fillna(0)\n",
    "all_sides[\"exports\"] = all_sides.exports.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "side_count = disputes.groupby([\"DispNum3\", \"DispNum4\"], as_index=False).agg({\"NumA\": sum, \"NumB\": sum})\n",
    "side_count[\"Country_Count\"] = side_count.apply(lambda row: row[\"NumA\"] + row[\"NumB\"], axis=1)\n",
    "side_count = side_count.drop([\"NumA\", \"NumB\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sides = all_sides.merge(side_count, on=[\"DispNum3\", \"DispNum4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revisionist_df = dispute_part.groupby([\"DispNum3\", \"DispNum4\"], as_index=False).agg({\"RevState\": sum})\n",
    "all_sides = all_sides.merge(revisionist_df, on=[\"DispNum3\", \"DispNum4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = all_sides[all_sides.Major_Dispute ==1]\n",
    "y = all_sides[all_sides.Major_Dispute ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.41351888667992"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "milper             int64\n",
       "irst               int64\n",
       "exports          float64\n",
       "Country_Count      int64\n",
       "Recip              int64\n",
       "MaxDur             int64\n",
       "milex              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_sides[\"Major_Dispute\"]\n",
    "# X = all_sides[[\"milex\", \"milper\", \"irst\", \"tpop\", \"upop\"]]\n",
    "X = all_sides[[\"milper\", \"irst\", \"exports\", \"Country_Count\", \"Recip\", \"MaxDur\", \"milex\"]]\n",
    "len(disputes[disputes.HostLev==3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DispNum3', 'DispNum4', 'StDay', 'StMon', 'StYear', 'EndDay', 'EndMon',\n",
       "       'EndYear', 'Outcome', 'Settle', 'Fatality', 'FatalPre', 'MaxDur',\n",
       "       'MinDur', 'HiAct', 'HostLev', 'Recip', 'NumA', 'NumB', 'Link1', 'Link2',\n",
       "       'Link3', 'Ongo2010', 'Version', 'Major_Dispute', 'milex', 'milper',\n",
       "       'irst', 'tpop', 'upop', 'imports', 'exports', 'Country_Count',\n",
       "       'RevState'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X,y)\n",
    "recall = cross_val_score(rfc, X, y, cv=10, scoring='recall').mean()\n",
    "precision = cross_val_score(rfc, X, y, cv=10, scoring='precision').mean()\n",
    "accuracy = cross_val_score(rfc, X, y, cv=10, scoring='accuracy').mean()\n",
    "f1 = cross_val_score(rfc, X, y, cv=10, scoring='f1').mean()\n",
    "y_pred = rfc.predict(X)\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts, accuracy, precision\n",
    "all_sides.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53077014096758524"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "logreg.fit(X, y)\n",
    "y_pred = logreg.predict(X)\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_disputes= all_sides[all_sides.Major_Dispute == 1]\n",
    "len(major_disputes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_major_events = all_sides[all_sides.Major_Dispute == 0]\n",
    "len(non_major_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "major_disp_x = major_disputes[\"Major_Dispute\"]\n",
    "major_disp_y = major_disputes[[\"irst\", \"milper\", \"upop\", \"imports\", \"exports\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_major_x = non_major_events[\"Major_Dispute\"]\n",
    "non_major_y = non_major_events[[\"irst\", \"milper\", \"upop\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 1703)"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_sides[[\"Major_Dispute\",\"milper\", \"irst\", \"exports\",\"imports\", \"Country_Count\", \n",
    "                \"Recip\", \"MaxDur\", \"milex\", \"RevState\"]]\n",
    "train,test = train_test_split(df, test_size=.3, random_state=42, stratify=df[\"Major_Dispute\"])\n",
    "len(test), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "major_train = train[train.Major_Dispute == 1]\n",
    "non_major_train = train[train.Major_Dispute == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 1408)"
      ]
     },
     "execution_count": 1201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(major_train), len(non_major_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_major_resampled = resample(major_train, replace=True, n_samples=1408, random_state=123)\n",
    "# training_df = pd.concat([non_major_train, df_major_resampled])\n",
    "df_non_major_resampled = resample(non_major_train, replace=False, n_samples=295, random_state=123)\n",
    "training_df = pd.concat([df_non_major_resampled, major_train])\n",
    "X_train = training_df[[\"milper\", \"irst\", \"Country_Count\", \"Recip\", \"milex\", \"exports\", \"RevState\", \"imports\"]]\n",
    "y_train = training_df[\"Major_Dispute\"]\n",
    "X_test = test[[\"milper\", \"irst\", \"Country_Count\", \"Recip\", \"milex\", \"exports\", \"RevState\", \"imports\"]]\n",
    "y_test = test[\"Major_Dispute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.358\n",
      "Recall Score: 0.683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 490, 1: 240})"
      ]
     },
     "execution_count": 1362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(\"Precision Score: {0:.3f}\".format(metrics.precision_score(y_test, y_pred)))\n",
    "print(\"Recall Score: {0:.3f}\".format(metrics.recall_score(y_test, y_pred)))\n",
    "#print(metrics.classification_report(y_test, y_pred))\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall--how many of the disputes I catch\n",
    "precision--guessed disputes/total disputes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 1250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = all_sides[[\"milper\", \"irst\", \"Country_Count\", \"milex\", \"Recip\"]]\n",
    "y = all_sides[\"Major_Dispute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28301887  0.22857143  0.22857143  0.19047619]\n",
      "0.232659478886\n"
     ]
    }
   ],
   "source": [
    "sv = SVC(class_weight=\"balanced\")\n",
    "logreg = LogisticRegression()\n",
    "a = cross_val_score(rfc, X, y, cv=4, scoring='recall')\n",
    "print(a)\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (<ipython-input-1363-1553e6cd93f0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1363-1553e6cd93f0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    f\"{hello}\": cross_val_score(rfc, X, y, cv=4, scoring='recall')\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
